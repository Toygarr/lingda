{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2OxTqPu0ZaL"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.35.2 torch==2.1.0 pandas==1.5.3 scikit-learn==1.2.2 tqdm==4.66.1 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnYEZtDv1GZE"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
        "from transformers import AutoTokenizer, BertModel\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuBs8tuYO0OX"
      },
      "outputs": [],
      "source": [
        "# ARGs\n",
        "datasets_path = Path('.')\n",
        "train_filename = 'train.csv'\n",
        "val_filename = 'valid.csv'\n",
        "test_filename = 'test.csv'\n",
        "\n",
        "bert_ckpt = 'bert-base-uncased'\n",
        "max_length = 200\n",
        "best_ckpt_name = 'best_model.pt'\n",
        "num_epochs = 5\n",
        "batch_size = 32\n",
        "lr = 5e-4\n",
        "validation_ratio = 0.1 # used if `val_filename` doesn't exist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU6lHmbl0rbu"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-x0IRyyP1abA"
      },
      "outputs": [],
      "source": [
        "def transform_remove_URL(text):\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url.sub(r'', text)\n",
        "\n",
        "\n",
        "def transform_remove_html(text):\n",
        "    html = re.compile(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
        "    return re.sub(html, '', text)\n",
        "\n",
        "\n",
        "def transform_remove_usernames(text):\n",
        "    uh = re.compile(r'([@][A-Za-z0-9_]+)|(\\w+:\\/\\/\\S+)')\n",
        "    return uh.sub(r'', text)\n",
        "\n",
        "\n",
        "def transform_remove_hashtags(text):\n",
        "    return re.sub(r'#\\w+', ' ', text)\n",
        "\n",
        "\n",
        "def transform_remove_digits(text):\n",
        "    return re.sub(r'\\d+', ' ', text)\n",
        "\n",
        "\n",
        "def transform_remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               u\"\\U0001f926-\\U0001f937\"\n",
        "                               u\"\\U00010000-\\U0010ffff\"\n",
        "                               u\"\\u2640-\\u2642\"\n",
        "                               u\"\\u2600-\\u2B55\"\n",
        "                               u\"\\u200d\"\n",
        "                               u\"\\u23cf\"\n",
        "                               u\"\\u23e9\"\n",
        "                               u\"\\u231a\"\n",
        "                               u\"\\ufe0f\"  # dingbats\n",
        "                               u\"\\u3030\"\n",
        "                               \"]+\", re.UNICODE)\n",
        "    return emoji_pattern.sub(r' ', text)\n",
        "\n",
        "\n",
        "def transform_lowercase(text):\n",
        "    return text.lower()\n",
        "\n",
        "\n",
        "def transform_fix_i(text):\n",
        "    fix = re.compile(r'iÌ‡')\n",
        "    return fix.sub(r'i', text)\n",
        "\n",
        "\n",
        "def transform_fix_whitespace(text):\n",
        "    return ' '.join(text.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRxnYrL50iux"
      },
      "outputs": [],
      "source": [
        "def apply_transforms(text, transforms):\n",
        "    for transform in transforms:\n",
        "        text = transform(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuVlt1dt1iud"
      },
      "outputs": [],
      "source": [
        "# Define transformations\n",
        "transforms = [\n",
        "    transform_remove_URL,\n",
        "    transform_remove_html,\n",
        "    transform_remove_usernames,\n",
        "    transform_remove_emoji,\n",
        "    transform_lowercase,\n",
        "    transform_fix_i,\n",
        "    transform_fix_whitespace,\n",
        "]\n",
        "\n",
        "# Load and preprocess data\n",
        "train_path = datasets_path / train_filename\n",
        "val_path = datasets_path / val_filename\n",
        "test_path = datasets_path / test_filename\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "has_validation = False\n",
        "\n",
        "if val_path.exists():\n",
        "    val_df = pd.read_csv(val_path)\n",
        "    has_validation = True\n",
        "\n",
        "\n",
        "train_df['text'] = train_df['text'].apply(lambda x: apply_transforms(x, transforms))\n",
        "train_df['text'] = train_df['text'].astype(str)\n",
        "\n",
        "test_df['text'] = test_df['text'].apply(lambda x: apply_transforms(x, transforms))\n",
        "test_df['text'] = test_df['text'].astype(str)\n",
        "\n",
        "if has_validation:\n",
        "    val_df['text'] = val_df['text'].apply(lambda x: apply_transforms(x, transforms))\n",
        "    val_df['text'] = val_df['text'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU9WrVC84L1F"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "x_train, y_train = train_df['text'], train_df['label']\n",
        "le.fit(y_train.tolist())\n",
        "y_train = le.transform(y_train.tolist())\n",
        "y_train = y_train.reshape(-1,1).ravel()\n",
        "\n",
        "\n",
        "x_test, y_test = test_df['text'], test_df['label']\n",
        "y_test = le.transform(y_test.tolist())\n",
        "y_test = y_test.reshape(-1,1).ravel()\n",
        "\n",
        "if has_validation:\n",
        "    x_dev, y_dev = val_df['text'], val_df['label']\n",
        "    y_dev = le.transform(y_dev.tolist())\n",
        "    y_dev = y_dev.reshape(-1,1).ravel()\n",
        "else:\n",
        "    x_train, x_dev, y_train, y_dev = train_test_split(x_train, y_train, test_size = validation_ratio, random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t30E_gSO5DJc"
      },
      "source": [
        "## Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYMLZaPA6QEq"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKtm42_R5FmV"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(bert_ckpt)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = TextDataset(x_train.tolist(), y_train.tolist(), tokenizer, max_length=max_length)\n",
        "dev_dataset = TextDataset(x_dev.tolist(), y_dev.tolist(), tokenizer, max_length=max_length)\n",
        "test_dataset = TextDataset(x_test.tolist(), y_test.tolist(), tokenizer, max_length=max_length)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmX0DlJv4-Dj"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEkXx-KD5AK2"
      },
      "outputs": [],
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.bert_encoder = BertModel.from_pretrained(model_name)\n",
        "        for param in self.bert_encoder.parameters():  # Freeze BERT\n",
        "            param.requires_grad = False\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.conv1d = nn.Conv1d(768, 32, kernel_size=3, padding='same')\n",
        "        self.lstm = nn.LSTM(32, 100, bidirectional=True, batch_first=True)\n",
        "        self.dropout_final = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(200, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        last_hidden_states = self.bert_encoder(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
        "        x = self.dropout(last_hidden_states.transpose(1, 2))\n",
        "        x = self.conv1d(x).transpose(1, 2)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.dropout_final(x[:, -1, :])  # We want the last time step\n",
        "        outputs = self.fc(x)\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sb9AL7OZ_1mz"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JN-zmJXbmP1Z"
      },
      "outputs": [],
      "source": [
        "# Initialize the model and move it to the device\n",
        "model = MyModel(bert_ckpt).to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def test_model(model, data_loader, split_name):\n",
        "    model.eval()\n",
        "    true_labels, predicted_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader, desc=f\"Testing on {split_name}\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            predictions = logits.squeeze() > 0\n",
        "\n",
        "            true_labels.extend(labels.int().cpu().numpy())\n",
        "            predicted_labels.extend(predictions.cpu().numpy())\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(true_labels, predicted_labels),\n",
        "        'recall_macro': recall_score(true_labels, predicted_labels, average='macro'),\n",
        "        'recall_negative': recall_score(true_labels, predicted_labels, pos_label=0, average='binary'),\n",
        "        'f1_score': f1_score(true_labels, predicted_labels, average='binary')\n",
        "    }\n",
        "\n",
        "    print(f\"{split_name} - Accuracy: {metrics['accuracy']}, Recall (Macro): {metrics['recall_macro']}, Negative Recall: {metrics['recall_negative']}, F1 Score (Binary): {metrics['f1_score']}\")\n",
        "    return metrics\n",
        "\n",
        "def train_model(model, train_loader, dev_loader, num_epochs, best_ckpt_name):\n",
        "    best_recall = 0.0\n",
        "\n",
        "    # Test on dev before starting training\n",
        "    test_model(model, dev_loader, \"Dev Split (Pre-Training)\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch}\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = criterion(logits.squeeze(), labels.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch}: Loss - {avg_loss}\")\n",
        "\n",
        "        # Test on dev split after each training epoch\n",
        "        dev_metrics = test_model(model, dev_loader, f\"Dev Split ({epoch+1}. epoch)\")\n",
        "\n",
        "        # Check if this is the best model so far and save it\n",
        "        if dev_metrics['recall_macro'] > best_recall:\n",
        "            best_recall = dev_metrics['recall_macro']\n",
        "            torch.save(model.state_dict(), best_ckpt_name)\n",
        "            print(f\"Saved new best model with recall: {best_recall}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuWov5YiStM2"
      },
      "outputs": [],
      "source": [
        "train_model(model, train_loader, dev_loader, num_epochs, best_ckpt_name)\n",
        "test_model(model, test_loader, 'Test Split')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
