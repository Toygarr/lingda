{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#For EDA\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Packages for general use throughout the notebook.\nimport random\nimport warnings\nimport time\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\n\n# to see columns properly\npd.set_option('display.max_colwidth', None)\n\n# for build our model\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Add, GlobalAvgPool1D, MaxPool1D, Activation, BatchNormalization, Embedding, LSTM, Dense, Bidirectional, Input, SpatialDropout1D, Dropout, Conv1D\nfrom tensorflow.keras import Model\nfrom transformers import BertTokenizer, TFBertModel\nfrom tensorflow.keras.activations import relu\n\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n\n#!pip install datasets\nfrom datasets import load_dataset\n\n# Input data files are available in the read-only \"../input/\" directory\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-28T20:31:03.923657Z","iopub.execute_input":"2022-04-28T20:31:03.924205Z","iopub.status.idle":"2022-04-28T20:31:11.791038Z","shell.execute_reply.started":"2022-04-28T20:31:03.924086Z","shell.execute_reply":"2022-04-28T20:31:11.789395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import data\n### Our and Coltekin's dataset\n","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/offensive-main/main/train.csv\")\ndev = pd.read_csv(\"../input/offensive-main/main/dev.csv\")\ntest = pd.read_csv(\"../input/offensive-main/main/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:17:31.597685Z","iopub.execute_input":"2022-04-28T19:17:31.597950Z","iopub.status.idle":"2022-04-28T19:17:31.864499Z","shell.execute_reply.started":"2022-04-28T19:17:31.597915Z","shell.execute_reply":"2022-04-28T19:17:31.863802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fix Headers\n\nRetrieve the original dataset and fix the headers to make it more comprehensible.","metadata":{}},{"cell_type":"code","source":"original_dataset = load_dataset(\"offenseval2020_tr\")\norg_train = pd.DataFrame(original_dataset['train'])\norg_train = org_train[:28000]\norg_test = pd.DataFrame(original_dataset['test'])\norg_train.rename(columns={'tweet': 'text', 'subtask_a': 'label'}, inplace=True)\norg_test.rename(columns={'tweet': 'text', 'subtask_a': 'label'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:17:31.865819Z","iopub.execute_input":"2022-04-28T19:17:31.866080Z","iopub.status.idle":"2022-04-28T19:17:41.861258Z","shell.execute_reply.started":"2022-04-28T19:17:31.866048Z","shell.execute_reply":"2022-04-28T19:17:41.860541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Our and Coltekin's normalized dataset","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/last-normalized-data/normalized/normalized_train.csv\")\ndev = pd.read_csv(\"../input/last-normalized-data/normalized/normalized_dev.csv\")\ntest = pd.read_csv(\"../input/last-normalized-data/normalized/normalized_test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-28T20:31:11.792804Z","iopub.execute_input":"2022-04-28T20:31:11.793148Z","iopub.status.idle":"2022-04-28T20:31:12.140586Z","shell.execute_reply.started":"2022-04-28T20:31:11.793108Z","shell.execute_reply":"2022-04-28T20:31:12.139686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"org_train = pd.read_csv(\"../input/last-normalized-data/normalized_coltekin/normalized_coltekin_train.csv\")\norg_test = pd.read_csv(\"../input/last-normalized-data/normalized_coltekin/normalized_coltekin_test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cleaning Functions\n\nWe provide several cleaning functions:\n* Removing URLs\n* Removing HTML Tags\n* Removing Usernames\n* Removing Emojis\n* fix_i -- it's basically used for a observed problem in the last dataset. There were lots of \"i̇\" character which can be considered as noise in Turkish text. We simply converted those to normal \"i\". (Most probably the problem is occured because of text retriever tool.)","metadata":{}},{"cell_type":"code","source":"import re\ndef remove_URL(text):\n    url = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url.sub(r'', text)\n\ndef remove_html(text):\n    html = re.compile(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n    return re.sub(html, '', text)\n\ndef remove_usernames(text):\n    uh = re.compile(r'([@][A-Za-z0-9_]+)|(\\w+:\\/\\/\\S+)')\n    return uh.sub(r'', text)\n\ndef remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n        u\"\\U00002500-\\U00002BEF\"  # chinese char\n        u\"\\U00002702-\\U000027B0\"\n        u\"\\U00002702-\\U000027B0\"\n        u\"\\U000024C2-\\U0001F251\"\n        u\"\\U0001f926-\\U0001f937\"\n        u\"\\U00010000-\\U0010ffff\"\n        u\"\\u2640-\\u2642\" \n        u\"\\u2600-\\u2B55\"\n        u\"\\u200d\"\n        u\"\\u23cf\"\n        u\"\\u23e9\"\n        u\"\\u231a\"\n        u\"\\ufe0f\"  # dingbats\n        u\"\\u3030\"\n                      \"]+\", re.UNICODE)\n    return emoji_pattern.sub(r' ', text)\n\ndef fix_i(text):\n    fix = re.compile(r'i̇')\n    return fix.sub(r'i', text)\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:19:48.853724Z","iopub.execute_input":"2022-04-28T19:19:48.854008Z","iopub.status.idle":"2022-04-28T19:19:48.865114Z","shell.execute_reply.started":"2022-04-28T19:19:48.853977Z","shell.execute_reply":"2022-04-28T19:19:48.864248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- You can investigate the impacts of preprocessing by simply removing the specific functions","metadata":{}},{"cell_type":"code","source":"# Applying helper functions to our sets\ntrain['text'] = train['text'].apply(lambda x: remove_URL(x))\ntrain['text'] = train['text'].apply(lambda x: remove_html(x))\ntrain['text'] = train['text'].apply(lambda x: remove_usernames(x))\ntrain['text'] = train['text'].apply(lambda x: remove_emoji(x))\ntrain['text'] = train['text'].str.lower()\ntrain['text'] = train['text'].apply(lambda x: fix_i(x))\ndev['text'] = dev['text'].apply(lambda x: remove_URL(x))\ndev['text'] = dev['text'].apply(lambda x: remove_html(x))\ndev['text'] = dev['text'].apply(lambda x: remove_usernames(x))\ndev['text'] = dev['text'].apply(lambda x: remove_emoji(x))\ndev['text'] = dev['text'].str.lower()\ndev['text'] = dev['text'].apply(lambda x: fix_i(x))\ntest['text'] = test['text'].apply(lambda x: remove_URL(x))\ntest['text'] = test['text'].apply(lambda x: remove_html(x))\ntest['text'] = test['text'].apply(lambda x: remove_usernames(x))\ntest['text'] = test['text'].apply(lambda x: remove_emoji(x))\ntest['text'] = test['text'].str.lower()\ntest['text'] = test['text'].apply(lambda x: fix_i(x))\n\n# Applying helper functions to original sets\norg_train['text'] = org_train['text'].apply(lambda x: remove_URL(x))\norg_train['text'] = org_train['text'].apply(lambda x: remove_html(x))\norg_train['text'] = org_train['text'].apply(lambda x: remove_usernames(x))\norg_train['text'] = org_train['text'].apply(lambda x: remove_emoji(x))\norg_train['text'] = org_train['text'].str.lower()\norg_train['text'] = org_train['text'].apply(lambda x: fix_i(x))\norg_test['text'] = org_test['text'].apply(lambda x: remove_URL(x))\norg_test['text'] = org_test['text'].apply(lambda x: remove_html(x))\norg_test['text'] = org_test['text'].apply(lambda x: remove_usernames(x))\norg_test['text'] = org_test['text'].apply(lambda x: remove_emoji(x))\norg_test['text'] = org_test['text'].str.lower()\norg_test['text'] = org_test['text'].apply(lambda x: fix_i(x))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:19:49.007729Z","iopub.execute_input":"2022-04-28T19:19:49.008303Z","iopub.status.idle":"2022-04-28T19:19:52.840742Z","shell.execute_reply.started":"2022-04-28T19:19:49.008272Z","shell.execute_reply":"2022-04-28T19:19:52.839989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"org_train[150:160]","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:19:52.842442Z","iopub.execute_input":"2022-04-28T19:19:52.842703Z","iopub.status.idle":"2022-04-28T19:19:52.863639Z","shell.execute_reply.started":"2022-04-28T19:19:52.842668Z","shell.execute_reply":"2022-04-28T19:19:52.862889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization","metadata":{}},{"cell_type":"code","source":"# Displaying target distribution of Toxic.\n\nfig, axes = plt.subplots(ncols=2, nrows=1, figsize=(12, 4), dpi=70)\nsns.countplot(train['label'], ax=axes[0])\naxes[1].pie(train['label'].value_counts(),\n            labels=[\"Not Toxic\", \"Toxic\"],\n            autopct='%1.2f%%',\n            shadow=True,\n            explode=(0.05, 0.05))\nfig.suptitle('Distribution of the Tweets', fontsize=24)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:19:52.864993Z","iopub.execute_input":"2022-04-28T19:19:52.865414Z","iopub.status.idle":"2022-04-28T19:19:53.170339Z","shell.execute_reply.started":"2022-04-28T19:19:52.865377Z","shell.execute_reply":"2022-04-28T19:19:53.169637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Phase\n\n* You will encounter 2 different models by in totally same structured. They are used for investigating the differences between Coltekin's dataset results and ours at the same time. (You can also download the weights by a code line we provided below of the model.)","metadata":{}},{"cell_type":"code","source":"os.environ[\"WANDB_API_KEY\"] = \"0\" ## to silence warning\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError:\n    strategy = tf.distribute.get_strategy() # for CPU and single GPU\n    print('Number of replicas:', strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T20:39:18.680141Z","iopub.execute_input":"2022-04-28T20:39:18.680638Z","iopub.status.idle":"2022-04-28T20:39:24.649291Z","shell.execute_reply.started":"2022-04-28T20:39:18.680572Z","shell.execute_reply":"2022-04-28T20:39:24.648399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hyperparameters\nmax_length = 200\nbatch_size = 128","metadata":{"execution":{"iopub.status.busy":"2022-04-28T20:39:24.651309Z","iopub.execute_input":"2022-04-28T20:39:24.651558Z","iopub.status.idle":"2022-04-28T20:39:24.656594Z","shell.execute_reply.started":"2022-04-28T20:39:24.651520Z","shell.execute_reply":"2022-04-28T20:39:24.655744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"dbmdz/bert-base-turkish-128k-uncased\"\ntokenizer = BertTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T20:39:24.658475Z","iopub.execute_input":"2022-04-28T20:39:24.658803Z","iopub.status.idle":"2022-04-28T20:39:26.570980Z","shell.execute_reply.started":"2022-04-28T20:39:24.658772Z","shell.execute_reply":"2022-04-28T20:39:26.570024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bert_encode(data):\n    tokens = tokenizer.batch_encode_plus(data, max_length=max_length, padding='max_length', truncation=True)\n    \n    return tf.constant(tokens['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2022-04-28T20:39:26.573154Z","iopub.execute_input":"2022-04-28T20:39:26.573420Z","iopub.status.idle":"2022-04-28T20:39:26.578522Z","shell.execute_reply.started":"2022-04-28T20:39:26.573389Z","shell.execute_reply":"2022-04-28T20:39:26.577505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_encoded = bert_encode(train.text)\ndev_encoded = bert_encode(dev.text)\norg_train_encoded = bert_encode(org_train.text)\n\norg_train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((org_train_encoded, org_train.label))\n    .shuffle(64)\n    .batch(batch_size)\n)\n\ntrain_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_encoded, train.label))\n    .shuffle(64)\n    .batch(batch_size)\n)\n\ndev_dataset = (\n    tf.data.Dataset\n   .from_tensor_slices((dev_encoded, dev.label))\n   .shuffle(64)\n   .batch(batch_size)\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T20:39:26.580289Z","iopub.execute_input":"2022-04-28T20:39:26.580918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model():\n    \n    bert_encoder = TFBertModel.from_pretrained(model_name)\n    input_word_ids = Input(shape=(max_length,), dtype=tf.int32, name=\"input_ids\")\n    last_hidden_states = bert_encoder(input_word_ids)[0]\n    x = SpatialDropout1D(0.2)(last_hidden_states)\n    x = Conv1D(32, 3, activation='relu', padding='same')(x)\n    x = Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2))(x)\n    x = Dropout(0.1)(x)\n    outputs = Dense(1, activation='sigmoid')(x)\n    model = Model(input_word_ids, outputs)\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = model()\n    adam_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n    model.compile(loss='binary_crossentropy', optimizer=adam_optimizer, metrics=['accuracy'])\n\n    model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\ncallbacks = [ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n              EarlyStopping(monitor='val_acc', min_delta=1e-5, patience=5)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Start train\nhistory = model.fit(\n    train_dataset,\n    batch_size=batch_size,\n    epochs=18,\n    validation_data=dev_dataset,\n    verbose=1,\n    callbacks = callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:23:53.578166Z","iopub.execute_input":"2022-04-28T07:23:53.578716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_graphs(history, string):\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string, 'val_'+string])\n    plt.show()\nplot_graphs(history, \"accuracy\")\nplot_graphs(history, \"loss\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Save of load the model.","metadata":{}},{"cell_type":"code","source":"#model.save_weights(f'offensive_weights_new_train.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-10T19:40:02.890753Z","iopub.execute_input":"2022-04-10T19:40:02.891186Z","iopub.status.idle":"2022-04-10T19:40:06.439554Z","shell.execute_reply.started":"2022-04-10T19:40:02.89114Z","shell.execute_reply":"2022-04-10T19:40:06.438681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.load_weights('../input/offensive-weights/offensive_weights.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T20:39:02.495636Z","iopub.execute_input":"2022-04-28T20:39:02.495918Z","iopub.status.idle":"2022-04-28T20:39:02.926837Z","shell.execute_reply.started":"2022-04-28T20:39:02.495887Z","shell.execute_reply":"2022-04-28T20:39:02.925623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"___","metadata":{}},{"cell_type":"markdown","source":"- Original training model (which will be used for training Coltekin's original dataset)","metadata":{}},{"cell_type":"code","source":"def org_model():\n    \n    bert_encoder = TFBertModel.from_pretrained(model_name)\n    input_word_ids = Input(shape=(max_length,), dtype=tf.int32, name=\"input_ids\")\n    last_hidden_states = bert_encoder(input_word_ids)[0]\n    x = SpatialDropout1D(0.2)(last_hidden_states)\n    x = Conv1D(32, 3, activation='relu', padding='same')(x)\n    x = Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2))(x)\n    x = Dropout(0.1)(x)\n    outputs = Dense(1, activation='sigmoid')(x)\n    org_model = Model(input_word_ids, outputs)\n    \n    return org_model","metadata":{"execution":{"iopub.status.busy":"2022-04-10T19:57:26.675471Z","iopub.execute_input":"2022-04-10T19:57:26.67581Z","iopub.status.idle":"2022-04-10T19:57:26.68439Z","shell.execute_reply.started":"2022-04-10T19:57:26.67578Z","shell.execute_reply":"2022-04-10T19:57:26.683388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    org_model = org_model()\n    adam_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n    org_model.compile(loss='binary_crossentropy', optimizer=adam_optimizer, metrics=['accuracy'])\n\n    org_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T19:57:27.046224Z","iopub.execute_input":"2022-04-10T19:57:27.046561Z","iopub.status.idle":"2022-04-10T19:57:47.107529Z","shell.execute_reply.started":"2022-04-10T19:57:27.046528Z","shell.execute_reply":"2022-04-10T19:57:47.106478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Start train\nhistory2 = org_model.fit(\n    org_train_dataset,\n    batch_size=batch_size,\n    epochs=3,\n    validation_data=dev_dataset,\n    verbose=1,\n    callbacks = callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T19:57:47.111179Z","iopub.execute_input":"2022-04-10T19:57:47.111773Z","iopub.status.idle":"2022-04-10T20:01:54.956149Z","shell.execute_reply.started":"2022-04-10T19:57:47.111735Z","shell.execute_reply":"2022-04-10T20:01:54.954852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_graphs(history2, string):\n    plt.plot(history2.history[string])\n    plt.plot(history2.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string, 'val_'+string])\n    plt.show()\nplot_graphs(history2, \"accuracy\")\nplot_graphs(history2, \"loss\")","metadata":{"execution":{"iopub.status.busy":"2022-04-10T19:49:49.466388Z","iopub.execute_input":"2022-04-10T19:49:49.466629Z","iopub.status.idle":"2022-04-10T19:49:49.970536Z","shell.execute_reply.started":"2022-04-10T19:49:49.4666Z","shell.execute_reply":"2022-04-10T19:49:49.969502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"___","metadata":{}},{"cell_type":"markdown","source":"# Our Test Set","metadata":{}},{"cell_type":"code","source":"test_encoded = bert_encode(test.text)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_encoded)\n    .batch(batch_size)\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:21:33.385111Z","iopub.status.idle":"2022-04-28T19:21:33.385695Z","shell.execute_reply.started":"2022-04-28T19:21:33.385438Z","shell.execute_reply":"2022-04-28T19:21:33.385463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Original test encoding\n","metadata":{}},{"cell_type":"code","source":"org_test_encoded = bert_encode(org_test.text)\n\norg_test_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(org_test_encoded)\n    .batch(batch_size)\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:21:33.386873Z","iopub.status.idle":"2022-04-28T19:21:33.387420Z","shell.execute_reply.started":"2022-04-28T19:21:33.387185Z","shell.execute_reply":"2022-04-28T19:21:33.387208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.label.value_counts())\nprint(test.label.value_counts())\nprint(dev.label.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:21:33.388484Z","iopub.status.idle":"2022-04-28T19:21:33.389055Z","shell.execute_reply.started":"2022-04-28T19:21:33.388825Z","shell.execute_reply":"2022-04-28T19:21:33.388849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TEST\n- We get the results of model that trained on our dataset.","metadata":{}},{"cell_type":"code","source":"pred = model.predict(test_dataset, batch_size=batch_size)\ny_pred = tf.cast(tf.round(pred), tf.int32).numpy().flatten()\n\nprint('Precision: %.4f' % precision_score(test.label, y_pred))\nprint('Recall: %.4f' % recall_score(test.label, y_pred))\nprint('Accuracy: %.4f' % accuracy_score(test.label, y_pred))\nprint('F1 Score: %.4f' % f1_score(test.label, y_pred))\nprint(classification_report(test.label, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:21:33.390133Z","iopub.status.idle":"2022-04-28T19:21:33.390728Z","shell.execute_reply.started":"2022-04-28T19:21:33.390467Z","shell.execute_reply":"2022-04-28T19:21:33.390491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(org_test_dataset, batch_size=batch_size)\ny_pred = tf.cast(tf.round(pred), tf.int32).numpy().flatten()\n\nprint('Precision: %.4f' % precision_score(org_test.label, y_pred))\nprint('Recall: %.4f' % recall_score(org_test.label, y_pred))\nprint('Accuracy: %.4f' % accuracy_score(org_test.label, y_pred))\nprint('F1 Score: %.4f' % f1_score(org_test.label, y_pred, average='macro'))\nprint(classification_report(org_test.label, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:21:33.392006Z","iopub.status.idle":"2022-04-28T19:21:33.392599Z","shell.execute_reply.started":"2022-04-28T19:21:33.392362Z","shell.execute_reply":"2022-04-28T19:21:33.392387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize=20)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90, fontsize=16)\n    plt.yticks(tick_marks, classes, fontsize=16)\n\n    fmt = '.2f'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label', fontsize=12)\n    plt.xlabel('Predicted label', fontsize=12)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T19:51:31.761385Z","iopub.execute_input":"2022-04-10T19:51:31.761741Z","iopub.status.idle":"2022-04-10T19:51:31.773495Z","shell.execute_reply.started":"2022-04-10T19:51:31.761707Z","shell.execute_reply":"2022-04-10T19:51:31.772184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\ncnf_matrix = confusion_matrix(test.label, y_pred)\nplt.figure(figsize=(6,6))\nplot_confusion_matrix(cnf_matrix, classes=org_train.label.unique(), title=\"Confusion matrix\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T20:05:40.537474Z","iopub.execute_input":"2022-04-10T20:05:40.537977Z","iopub.status.idle":"2022-04-10T20:05:40.812024Z","shell.execute_reply.started":"2022-04-10T20:05:40.537939Z","shell.execute_reply":"2022-04-10T20:05:40.8111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Original trained model performance on our test set and original test set\n- We get the results of model that trained on Coltekin's dataset.","metadata":{}},{"cell_type":"code","source":"pred = org_model.predict(test_dataset, batch_size=batch_size)\ny_pred = tf.cast(tf.round(pred), tf.int32).numpy().flatten()\n\nprint('Precision: %.4f' % precision_score(test.label, y_pred, average='macro'))\nprint('Recall: %.4f' % recall_score(test.label, y_pred, average='macro'))\nprint('Accuracy: %.4f' % accuracy_score(test.label, y_pred))\nprint('F1 Score: %.4f' % f1_score(test.label, y_pred, average='macro'))\nprint(classification_report(test.label, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-04-10T20:05:36.582627Z","iopub.execute_input":"2022-04-10T20:05:36.582952Z","iopub.status.idle":"2022-04-10T20:05:39.464787Z","shell.execute_reply.started":"2022-04-10T20:05:36.582919Z","shell.execute_reply":"2022-04-10T20:05:39.463808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = org_model.predict(org_test_dataset, batch_size=batch_size)\ny_pred = tf.cast(tf.round(pred), tf.int32).numpy().flatten()\n\nprint('Precision: %.4f' % precision_score(org_test.label, y_pred))\nprint('Recall: %.4f' % recall_score(org_test.label, y_pred))\nprint('Accuracy: %.4f' % accuracy_score(org_test.label, y_pred))\nprint('F1 Score: %.4f' % f1_score(org_test.label, y_pred, average='macro'))\nprint(classification_report(org_test.label, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-04-10T20:02:12.050186Z","iopub.execute_input":"2022-04-10T20:02:12.050953Z","iopub.status.idle":"2022-04-10T20:02:18.224829Z","shell.execute_reply.started":"2022-04-10T20:02:12.050913Z","shell.execute_reply":"2022-04-10T20:02:18.222892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# More about different training models\n\nIt was important to validate our model pipeline with both our dataset and Coltekin's dataset, and that is why we train 2 different models and test on both \"our test set\" and \"Coltekin's test set\".\n\nThe test results are tried on both average macro and default. You can simply change it to see differences between results which we explained in the paper.\n\nAlso, the results and reasons are described in more depth and detail in the paper.","metadata":{}}]}